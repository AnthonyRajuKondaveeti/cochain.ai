# Render.com Blueprint Configuration
# Deploy CoChain.ai to Render's free tier (512MB RAM)

services:
  # Main web service
  - type: web
    name: cochain-ai
    runtime: python
    region: oregon  # Choose closest region to your users
    plan: free  # Free tier: 512MB RAM, sleeps after 15 min inactivity
    branch: main  # Deploy from main branch
    
    # Build configuration
    buildCommand: pip install -r requirements-light.txt
    
    # Start command (gunicorn with optimized worker settings)
    startCommand: gunicorn app:app --workers 1 --threads 4 --timeout 120 --bind 0.0.0.0:$PORT --access-logfile - --error-logfile -
    
    # Health check configuration
    healthCheckPath: /
    
    # Environment variables
    envVars:
      # Supabase configuration (add values in Render dashboard)
      - key: SUPABASE_URL
        sync: false
      
      - key: SUPABASE_KEY
        sync: false
      
      - key: SUPABASE_SERVICE_KEY
        sync: false
      
      # Flask secret key (auto-generated secure value)
      - key: SECRET_KEY
        generateValue: true
      
      # HuggingFace API key for embeddings (add in Render dashboard)
      - key: HUGGINGFACE_API_KEY
        sync: false
      
      # Python configuration
      - key: PYTHON_VERSION
        value: 3.12.0
      
      # Optimization flags
      - key: PYTHONUNBUFFERED
        value: 1
      
      # Disable unnecessary features
      - key: USE_RL_RECOMMENDATIONS
        value: true
      
      - key: ENABLE_AUTO_TRAINING
        value: false

# Deployment notes:
# 1. Get HuggingFace API key: https://huggingface.co/settings/tokens (free tier: 30K requests/month)
# 2. Add environment variables in Render dashboard
# 3. Free tier limitations:
#    - 512MB RAM (sufficient with requirements-light.txt)
#    - Service sleeps after 15 minutes of inactivity (cold start: ~30 seconds)
#    - 750 hours/month free (reduces to 100 hours without payment method)
# 4. Monitor logs for 503 errors during HuggingFace model loading (auto-retry enabled)
