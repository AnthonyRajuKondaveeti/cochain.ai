# CoChain.ai Environment Variables
# Copy this file to .env and fill in your actual values

# ==================== DATABASE ====================
# Supabase Configuration
SUPABASE_URL=https://your-project-id.supabase.co
SUPABASE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...  # Anon/Public Key
SUPABASE_SERVICE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...  # Service Role Key (Admin)

# ==================== APPLICATION ====================
# Flask Secret Key (generate with: python -c "import os; print(os.urandom(24).hex())")
SECRET_KEY=your-secret-key-here-32-characters-minimum

# Admin Configuration (comma-separated email addresses)
ADMIN_EMAILS=your-email@example.com

# Flask Environment (development or production)
FLASK_ENV=development

# Port (default: 5000, Render uses dynamic $PORT)
PORT=5000

# ==================== ML / EMBEDDINGS ====================
# HuggingFace API Key (for low-RAM deployment)
# Get from: https://huggingface.co/settings/tokens
# Leave empty to use local sentence-transformers (requires 1.3GB RAM)
HUGGINGFACE_API_KEY=hf_your_token_here

# ==================== FEATURES ====================
# Use RL-enhanced recommendations (True) or baseline similarity-only (False)
USE_RL_RECOMMENDATIONS=true

# Enable automatic RL training (False recommended for A/B testing)
ENABLE_AUTO_TRAINING=false

# ==================== LOGGING ====================
# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# ==================== NOTES ====================
# Development Setup:
#   1. Copy this file: cp .env.example .env
#   2. Fill in your Supabase credentials
#   3. Leave HUGGINGFACE_API_KEY empty to use local models
#   4. Run: python app.py
#
# Production Setup (Render):
#   1. Don't commit .env to git
#   2. Set environment variables in Render dashboard
#   3. MUST set HUGGINGFACE_API_KEY for 512MB RAM deployment
#   4. Set FLASK_ENV=production
#   5. Generate strong SECRET_KEY (or let Render auto-generate)
#
# Memory Usage:
#   - With HUGGINGFACE_API_KEY: ~360MB (fits 512MB free tier)
#   - Without (local models): ~1.6GB (needs paid tier)
